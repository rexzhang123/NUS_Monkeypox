# -*- coding: utf-8 -*-
"""monkeypoxTwitter

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J3SodwMm9DMqW5g6DX4NmsIwxi95_viS
"""

from google.colab import drive
drive.mount('/content/drive')

# Import Libraries
 
from textblob import TextBlob
import sys
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import os
import re
import string
import seaborn as sns
 
import nltk
nltk.downloader.download('vader_lexicon')
 
from wordcloud import WordCloud, STOPWORDS
from PIL import Image
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.stem import SnowballStemmer

from nltk.sentiment.vader import SentimentIntensityAnalyzer
from sklearn.feature_extraction.text import CountVectorizer

# load dataset and create dataframe
tweets_info = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/datasets/combinedTweetIDs.csv")

# print(tweets_info.head())
print(tweets_info.shape)
print(tweets_info.columns)


# keep only the relevant column names
tweets_info = tweets_info.loc[:, ['lang', 'text', 'user_location']]

print("shape of tweets_info after only keeping relevant columns")
print("\n")
print(tweets_info.shape)
print(tweets_info.head())

# dropping duplicates

print("before dropping duplicates")
print(tweets_info.shape)
tweets_info.drop_duplicates(inplace=True)
print("after dropping duplicates")
print(tweets_info.shape)

# dropping languages other than English 

print(tweets_info['lang'].unique()) 

tweets_info = tweets_info[tweets_info['lang'] == 'en']

print("\n tweets_info shape after dropping other languages: ")
print(tweets_info.shape)

tweets_info.isnull().sum()

# more EDA
pd.options.display.max_colwidth = 1300
print(tweets_info.iloc[1:10, 1])

# Removing RT, Punctuation etc
def remove_rt(x): return re.sub('RT @\w+: ', " ", x)
 
def rt(x): return re.sub(
    "(@[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)", " ", x)
 
tweets_info["text"] = tweets_info.text.map(remove_rt).map(rt)
tweets_info["text"] = tweets_info.text.str.lower()

# reset dataframe row index
tweets_info = tweets_info.reset_index(drop=True)

pd.options.display.max_colwidth = 1300
print(tweets_info.iloc[0:10, 1])

tweets_info[['polarity', 'subjectivity']] = tweets_info['text'].apply(
    lambda Text: pd.Series(TextBlob(Text).sentiment))

for index, row in tweets_info['text'].iteritems():
    score = SentimentIntensityAnalyzer().polarity_scores(row)
    neg = score['neg']
    neu = score['neu']
    pos = score['pos']
    comp = score['compound']
     
    if neg > pos:
        tweets_info.loc[index, 'sentiment'] = "negative"
    elif pos > neg:
        tweets_info.loc[index, 'sentiment'] = "positive"
    else:
        tweets_info.loc[index, 'sentiment'] = "neutral"
         
    tweets_info.loc[index, 'neg'] = neg
    tweets_info.loc[index, 'neu'] = neu
    tweets_info.loc[index, 'pos'] = pos
    tweets_info.loc[index, 'compound'] = comp

tweets_info[["text", "sentiment", "polarity",
        "subjectivity", "neg", "neu", "pos"]].head(5)

total_pos = len(tweets_info.loc[tweets_info['sentiment'] == "positive"])
total_neg = len(tweets_info.loc[tweets_info['sentiment'] == "negative"])
total_neu = len(tweets_info.loc[tweets_info['sentiment'] == "neutral"])
total_tweets = len(tweets_info)
print("Total Positive Tweets % : {:.2f}"
      .format((total_pos/total_tweets)*100))
print("Total Negative Tweets % : {:.2f}"
      .format((total_neg/total_tweets)*100))
print("Total Neutral Tweets % : {:.2f}"
      .format((total_neu/total_tweets)*100))

# Pie Chart showing percentage of each sentiment

mylabels = ["Positive", "Negative", "Neutral"]
mycolors = ["Green", "Red", "Blue"]
 
plt.figure(figsize=(8, 5),
           dpi=600)  # Push new figure on stack
myexplode = [0, 0.2, 0]
plt.pie([total_pos, total_neg, total_neu], colors=mycolors,
        labels=mylabels, explode=myexplode, autopct='%1.1f%%', startangle = 90)

plt.title('Distributon of Sentiment')
plt.show()

#Function to Create Wordcloud
def create_wordcloud(text):
 mask = np.array(Image.open("/content/drive/MyDrive/Colab Notebooks/cloud.png"))
 stopwords = set(STOPWORDS)
 wc = WordCloud(background_color="white", mask = mask, max_words=3000, stopwords=stopwords, repeat=True)
 wc.generate(str(text))
 wc.to_file("wc.png")
 print("Word Cloud Saved Successfully")
 path="wc.png"
 display(Image.open(path))

#Creating new data frames for all sentiments (positive, negative and neutral)
tw_list_negative = tweets_info[tweets_info["sentiment"]=="negative"]
tw_list_positive = tweets_info[tweets_info["sentiment"]=="positive"]
tw_list_neutral = tweets_info[tweets_info["sentiment"]=="neutral"]

#Creating wordcloud for all tweets
create_wordcloud(tweets_info["text"].values)

#Creating wordcloud for positive sentiment
create_wordcloud(tw_list_positive["text"].values)

#Creating wordcloud for negative sentiment
create_wordcloud(tw_list_negative["text"].values)

#Creating wordcloud for neutral sentiment
create_wordcloud(tw_list_neutral["text"].values)